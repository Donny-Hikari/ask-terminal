chat_terminal:
  endpoint: "local-llama"

  prompt: "prompts/chat-terminal.mext"
  user: "User"
  agent: "Assistant"

text_completion_endpoints:
  local-llama:
    server_url: "http://127.0.0.1:40080"
    params:
      temperature: 0.75
      top_k: 40
      top_p: 0.9
      n_predict: 4096
      stop:
        - "[INST]"
        - "[User]:"
  openai:
    model: "gpt-3.5-turbo"
    credentials: "credentials/openai.yaml"
    params:
      stop:
        - "[User]:"
